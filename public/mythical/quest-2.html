<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mystic LLM Guild - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="../assets/shared/quest-navigator.css">
    <link rel="stylesheet" href="../assets/theme-toggle.css">
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }

        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body class="theme-mythical">

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="https://github.com/Azure-Samples/azure-ai-travel-agents" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="../assets/shared/github-mark.svg" alt="GitHub" width="24" height="24">
                </a>
                <a href="index.html">The Enchanted Kingdom of Azure Agents</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Theme</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <button class="theme-toggle-btn" aria-label="Switch to light mode" type="button">
                    <div class="theme-toggle-slider">
                        <svg class="toggle-icon sun-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="4" fill="currentColor"/>
                            <path d="M12 2v2M12 20v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M2 12h2M20 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                        </svg>
                        <svg class="toggle-icon moon-icon" viewBox="0 0 24 24">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                        </svg>
                    </div>
                </button>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 2: The Enchanted LLM Provider Strategy</h1>
<hr>
<p>In the mystical Kingdom of Azure Agents, the council of AI sorcerers wields diverse magical scrolls to invoke the powers of legendary LLMs. Each scroll is enchanted to summon specific providers, from the Azure OpenAI archives to GitHub‚Äôs secret repositories and Ollama‚Äôs spellbinding models. At the heart of this harmony lies the <strong>Crystal of Orchestration</strong>, which ensures the right spell is cast based on the adventurer‚Äôs needs. Brave travelers must learn how these scrolls are selected and configured, mastering the art of dynamic LLM invocation.</p>
<h2>Key Takeaways</h2>
<p>After completing this quest, you will understand:</p>
<ul>
<li>üéØ <strong>Dynamic Provider Selection</strong>: How LLM providers are chosen based on runtime environment and configurations.</li>
<li>üîç <strong>Credential Management</strong>: How Azure credentials are used to authenticate LLM requests securely.</li>
<li>‚ö° <strong>Error Handling Patterns</strong>: How the system gracefully handles unknown providers and invalid configurations.</li>
<li>üí° <strong>Extensibility</strong>: How new LLM providers can be added seamlessly to the orchestration system.</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/index.ts</code></a></h3>
<p>The <code class="inline-code">index.ts</code> file serves as the magical tome that orchestrates LLM providers. It defines the <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm()</code></a> function, which dynamically selects the appropriate provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable. This ensures adventurers can summon the right LLM powers for their quests, whether they require Azure OpenAI, GitHub models, or Ollama‚Äôs enchantments.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm()</code></a> dynamically selects an LLM provider based on environment variables, ensuring flexibility in deployment scenarios.</li>
<li><code class="inline-code">LLMProvider</code> type defines valid provider options, creating a controlled vocabulary for provider selection.</li>
<li>Error handling ensures the system gracefully rejects unknown providers, guiding adventurers to valid configurations.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">type LLMProvider =
  | &quot;azure-openai&quot;
  | &quot;github-models&quot;
  | &quot;foundry-local&quot;
  | &quot;docker-models&quot;
  | &quot;ollama-models&quot;;

const provider = (process.env.LLM_PROVIDER || &quot;&quot;) as LLMProvider;

export const llm = async () =&gt; {
  switch (provider) {
    case &quot;azure-openai&quot;:
      return azureOpenAI();
    case &quot;github-models&quot;:
      return githubModels();
    case &quot;docker-models&quot;:
      return dockerModels();
    case &quot;ollama-models&quot;:
      return ollamaModels();
    case &quot;foundry-local&quot;:
      return foundryLocal();
    default:
      throw new Error(
        `Unknown LLM_PROVIDER &quot;${provider}&quot;. Valid options are: azure-openai, github-models, foundry-local, docker-models, ollama-models.`
      );
  }
};
</code></pre>
<ul>
<li>This code dynamically selects an LLM provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable, enabling flexibility in deployment.</li>
<li>The <code class="inline-code">LLMProvider</code> type ensures only valid provider names can be used, reducing configuration errors.</li>
<li>The error handling mechanism provides clear feedback when an invalid provider is specified, improving debugging efficiency.</li>
<li>The modular design makes it easy to add new providers by extending the switch statement and defining new functions.</li>
<li>This structure supports a plug-and-play model for introducing additional LLM integrations.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/azure-openai.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/azure-openai.ts</code></a></h3>
<p>This file contains the spell to invoke Azure OpenAI, using either an API key or Azure Managed Identity for authentication. It demonstrates the system‚Äôs ability to adapt to local and production environments, ensuring secure and reliable invocation of Azure‚Äôs cognitive services.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm()</code></a> detects the runtime environment and selects the appropriate authentication method.</li>
<li><code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code> provide secure access to Azure services in production environments.</li>
<li>API key authentication supports local development scenarios where managed identities are unavailable.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">const AZURE_COGNITIVE_SERVICES_SCOPE =
  &quot;https://cognitiveservices.azure.com/.default&quot;;

export const llm = async () =&gt; {
  console.log(&quot;Using Azure OpenAI&quot;);

  const isRunningInLocalDocker = process.env.IS_LOCAL_DOCKER_ENV === &quot;true&quot;;
  
  if (isRunningInLocalDocker) {
    console.log(
      &quot;Running in local Docker environment, Azure Managed Identity is not supported. Authenticating with apiKey.&quot;
    );
    
    return openai({
      azure: {
        endpoint: process.env.AZURE_OPENAI_ENDPOINT,
        deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
        apiKey: process.env.AZURE_OPENAI_API_KEY,
      },
    });
  }
  
  let credential: any = new DefaultAzureCredential();
  const clientId = process.env.AZURE_CLIENT_ID;
  if (clientId) {
    console.log(&quot;Using Azure Client ID:&quot;, clientId);
    credential = new ManagedIdentityCredential({ clientId });
  }

  const azureADTokenProvider = getBearerTokenProvider(
    credential,
    AZURE_COGNITIVE_SERVICES_SCOPE
  );

  return openai({
    azure: {
      azureADTokenProvider,
      endpoint: process.env.AZURE_OPENAI_ENDPOINT,
      deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
    },
  });
};
</code></pre>
<ul>
<li>The code adapts authentication based on the runtime environment, supporting both local and production scenarios.</li>
<li><code class="inline-code">DefaultAzureCredential</code> simplifies credential management by automatically selecting the best authentication method.</li>
<li>API key authentication ensures developers can test locally without requiring Azure Managed Identity.</li>
<li>The use of <code class="inline-code">ManagedIdentityCredential</code> provides secure access in production, reducing the risk of credential exposure.</li>
<li>The modular design makes it easy to extend authentication methods for additional Azure services.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/github-models.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/github-models.ts</code></a></h3>
<p>This file defines the invocation spell for GitHub-hosted models, showcasing how the system integrates external model repositories using API keys and custom endpoints.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm()</code></a> integrates GitHub-hosted models using an API key and model-specific configurations.</li>
<li>Base URL customization allows seamless integration with GitHub‚Äôs inference service.</li>
<li>The modular design ensures compatibility with other external model providers.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">export const llm = async () =&gt; {
  console.log(&quot;Using GitHub Models&quot;);
  return openai({
    baseURL: &quot;https://models.inference.ai.azure.com&quot;,
    apiKey: process.env.GITHUB_TOKEN,
    model: process.env.GITHUB_MODEL,
  });
};
</code></pre>
<ul>
<li>This code integrates GitHub-hosted models by specifying a base URL, API key, and model configuration.</li>
<li>The <code class="inline-code">baseURL</code> parameter enables compatibility with custom inference services, showcasing the system‚Äôs flexibility.</li>
<li>API key authentication ensures secure access to GitHub‚Äôs model repository.</li>
<li>The modular structure allows additional external model providers to be integrated with minimal changes.</li>
<li>This approach demonstrates how external services can be seamlessly incorporated into the orchestration system.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Study how environment variables are used to dynamically configure LLM providers in <code class="inline-code">index.ts</code>.</li>
<li>Observe how <code class="inline-code">azure-openai.ts</code> handles authentication securely, adapting to different runtime environments.</li>
<li>Explore the modular design of provider files to understand how new integrations can be added easily.</li>
</ul>
<h2>Try This</h2>
<p>Challenge yourself to deepen your understanding:</p>
<ol>
<li><strong>Add a New Provider</strong>: Create a new LLM provider file for a hypothetical service. Define its configuration and integrate it into the <code class="inline-code">index.ts</code> switch statement. Test its invocation with mock environment variables.</li>
<li><strong>Trace Provider Selection</strong>: Add logging statements to the <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm()</code></a> function in <code class="inline-code">index.ts</code> to trace how the provider is selected based on different environment configurations. Run the system with various <code class="inline-code">LLM_PROVIDER</code> values to observe its behavior.</li>
</ol>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries of the enchanted multi-agent system.</p>
<p>By the radiant light of the celestial ‚≠ê, the Mystic LLM Guild has triumphantly unlocked the first arcane milestone of wisdom‚Äî20% of the quest complete‚Äîforge ahead, valiant seekers, for the realms of knowledge await your heroic ascent! ‚ö°üíéüöÄ</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-1.html" class="prev-quest-btn">‚Üê Previous: Quest 1</a>
        <a href="quest-3.html" class="next-quest-btn">Next: Quest 3 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="../assets/shared/quest-navigator.js"></script>
    <!-- Theme Toggle Script (for light/dark mode toggle) -->
    <script src="../assets/theme-toggle.js"></script>
</body>
</html>