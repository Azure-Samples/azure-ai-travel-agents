<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Mystic LLM Forge - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="../assets/shared/quest-navigator.css">
    <link rel="stylesheet" href="../assets/theme-toggle.css">
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }
        
        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body class="theme-mythical">

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="https://github.com/Azure-Samples/azure-ai-travel-agents" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="../assets/shared/github-mark.svg" alt="GitHub" width="24" height="24">
                </a>
                <a href="index.html">The Enchanted Kingdom of Azure AI Travel Agents</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Theme</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <button class="theme-toggle-btn" aria-label="Switch to light mode" type="button">
                    <div class="theme-toggle-slider">
                        <svg class="toggle-icon sun-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="4" fill="currentColor"/>
                            <path d="M12 2v2M12 20v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M2 12h2M20 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                        </svg>
                        <svg class="toggle-icon moon-icon" viewBox="0 0 24 24">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                        </svg>
                    </div>
                </button>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 2: Flexible LLM Provider Strategy</h1>
<hr>
<p>In the heart of the Enchanted Kingdom, the Mystic LLM Forge hums with magical energy, summoning the wisdom of distant realms to empower the kingdom&#39;s Travel Agents. Here, the forge crafts enchanted models, each imbued with unique powers, to answer travelers&#39; queries. The Forge Master oversees the selection of mystical providers, ensuring harmony between Azure OpenAI, GitHub Models, and Ollama Models. Adventurer, your quest is to unveil the secrets of the forge&#39;s flexible strategies and understand how it adapts to the kingdom&#39;s needs.</p>
<h2>Quest Objectives</h2>
<p>As you explore the code below, investigate these key questions:</p>
<ul>
<li>üîç <strong>Provider Selection Ritual</strong>: How does the forge dynamically choose between different LLM providers based on environmental settings?</li>
<li>‚ö° <strong>Azure Enchantment Flow</strong>: What mechanisms enable Azure OpenAI authentication, including managed identity and API key fallback?</li>
<li>üõ°Ô∏è <strong>Error Safeguards</strong>: How does the system handle unknown provider configurations or missing credentials gracefully?</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix"><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/index.ts</a>:</span> LLM Provider Strategy</h3>
<p>This file orchestrates the selection of LLM providers for the Mystic Forge. Using environment variables, it dynamically determines which provider to invoke, ensuring flexibility and adaptability. The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function acts as the central spell that channels the chosen provider&#39;s magic, while the <code class="inline-code">LLMProvider</code> type defines valid options. The error handling mechanism ensures that invalid configurations are caught early, preventing disruptions to the kingdom&#39;s operations.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> dynamically selects the LLM provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable, ensuring flexibility in deployment.</li>
<li><code class="inline-code">LLMProvider</code> defines the valid options for provider selection, creating a clear boundary for supported configurations.</li>
<li>Error handling within <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> ensures invalid or unsupported providers are gracefully rejected, maintaining system integrity.</li>
</ul>
<h3><span class="header-prefix"><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/azure-openai.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/azure-openai.ts</a>:</span> Azure OpenAI Integration</h3>
<p>This file implements the Azure OpenAI provider, enabling the Mystic Forge to summon models hosted on Azure. It supports both API key authentication and Azure Managed Identity, adapting to different deployment environments. The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function dynamically configures the provider based on the environment, ensuring seamless integration.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> dynamically configures the Azure OpenAI provider based on environment variables, supporting both local and production deployments.</li>
<li><code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code> enable secure authentication using Azure identity services.</li>
<li><code class="inline-code">getBearerTokenProvider</code> generates tokens for accessing Azure Cognitive Services, ensuring secure communication.</li>
</ul>
<h3><span class="header-prefix"><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/ollama-models.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/ollama-models.ts</a>:</span> Ollama Models Integration</h3>
<p>This file integrates Ollama Models into the Mystic Forge, allowing it to utilize specialized tools for unique queries. The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function configures the provider with custom settings, including tool call support for enhanced functionality.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> configures the Ollama Models provider with specific endpoint and API key settings, enabling seamless integration.</li>
<li>Custom configuration includes <code class="inline-code">supportToolCall</code>, extending functionality for non-standard providers.</li>
<li>The provider setup demonstrates adaptability for integrating emerging LLM technologies.</li>
</ul>
<h2>Code</h2>
<h3><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/index.ts</a></h3>
<pre><code class="language-typescript">import dotenv from &quot;dotenv&quot;;
dotenv.config();

import { llm as azureOpenAI } from &quot;./azure-openai.js&quot;;
import { llm as githubModels } from &quot;./github-models.js&quot;;
import { llm as ollamaModels } from &quot;./ollama-models.js&quot;;

type LLMProvider =
  | &quot;azure-openai&quot;
  | &quot;github-models&quot;
  | &quot;ollama-models&quot;;

const provider = (process.env.LLM_PROVIDER || &quot;&quot;) as LLMProvider;

export const llm = async () =&gt; {
  switch (provider) {
    case &quot;azure-openai&quot;:
      return azureOpenAI();
    case &quot;github-models&quot;:
      return githubModels();
    case &quot;ollama-models&quot;:
      return ollamaModels();
    default:
      throw new Error(
        `Unknown LLM_PROVIDER &quot;${provider}&quot;. Valid options are: azure-openai, github-models, ollama-models.`
      );
  }
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function dynamically selects an LLM provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable.</li>
<li>Supported providers are defined by the <code class="inline-code">LLMProvider</code> type, ensuring clarity in configuration.</li>
<li>Error handling ensures unknown providers are gracefully rejected, preventing runtime failures.</li>
<li>Environment-driven configuration allows flexibility in deployment scenarios, adapting to local or production needs.</li>
<li>Modular imports enable easy extension by adding new providers without altering core logic.</li>
</ul>
<hr>
<h3><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/azure-openai.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/azure-openai.ts</a></h3>
<pre><code class="language-typescript">import { openai } from &quot;llamaindex&quot;;
import {
  DefaultAzureCredential,
  getBearerTokenProvider,
  ManagedIdentityCredential,
} from &quot;@azure/identity&quot;;

const AZURE_COGNITIVE_SERVICES_SCOPE =
  &quot;https://cognitiveservices.azure.com/.default&quot;;

export const llm = async () =&gt; {
  console.log(&quot;Using Azure OpenAI&quot;);

  const isRunningInLocalDocker = process.env.IS_LOCAL_DOCKER_ENV === &quot;true&quot;;
  
  if (isRunningInLocalDocker) {
    console.log(
      &quot;Running in local Docker environment, Azure Managed Identity is not supported. Authenticating with apiKey.&quot;
    );
    return openai({
      azure: {
        endpoint: process.env.AZURE_OPENAI_ENDPOINT,
        deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
        apiKey: process.env.AZURE_OPENAI_API_KEY,
      },
    });
  }
  
  let credential: any = new DefaultAzureCredential();
  const clientId = process.env.AZURE_CLIENT_ID;
  if (clientId) {
    console.log(&quot;Using Azure Client ID:&quot;, clientId);
    credential = new ManagedIdentityCredential({ clientId });
  }

  const azureADTokenProvider = getBearerTokenProvider(
    credential,
    AZURE_COGNITIVE_SERVICES_SCOPE
  );

  return openai({
    azure: {
      azureADTokenProvider,
      endpoint: process.env.AZURE_OPENAI_ENDPOINT,
      deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
    },
  });
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function dynamically configures Azure OpenAI integration based on environment variables.</li>
<li>API key authentication is used for local Docker environments, ensuring compatibility with local setups.</li>
<li><code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code> enable secure authentication for production environments.</li>
<li><code class="inline-code">getBearerTokenProvider</code> generates tokens for accessing Azure Cognitive Services, ensuring secure communication.</li>
<li>The modular design supports both local and production deployments seamlessly.</li>
</ul>
<hr>
<h3><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/ollama-models.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/ollama-models.ts</a></h3>
<pre><code class="language-typescript">import { OpenAI, openai } from &quot;llamaindex&quot;;

export const llm = async () =&gt; {
  console.log(&quot;Using Ollama Models&quot;);
  const provider = openai({
    baseURL: process.env.OLLAMA_MODEL_ENDPOINT,
    apiKey: &#39;OLLAMA_API_KEY&#39;,
    model: process.env.OLLAMA_MODEL,
  });
  return {
    ...provider,
    supportToolCall: true,
  } as OpenAI;
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function configures Ollama Models with specific endpoint and API key settings.</li>
<li>Custom configuration includes <code class="inline-code">supportToolCall</code>, extending functionality for non-standard providers.</li>
<li>Modular design enables easy integration of emerging LLM technologies.</li>
<li>The setup demonstrates adaptability for integrating providers with unique features.</li>
<li>Environment-driven configuration ensures flexibility in deployment scenarios.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Investigate how the <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function in <code class="inline-code">index.ts</code> dynamically selects providers based on environment variables.</li>
<li>Examine the use of <code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code> in <code class="inline-code">azure-openai.ts</code> to understand Azure authentication flows.</li>
<li>Explore how <code class="inline-code">supportToolCall</code> in <code class="inline-code">ollama-models.ts</code> extends functionality for non-standard providers.</li>
</ul>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries of the Mystic LLM Forge.</p>
<p>Brave seeker of wisdom, you have kindled the first ember of enlightenment within the Mystic LLM Forge, a feat worthy of legends‚Äîpress on, for the stars themselves whisper of your destined mastery! ‚ö°üíéüì°</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-1.html" class="prev-quest-btn">‚Üê Previous: Quest 1</a>
        <a href="quest-3.html" class="next-quest-btn">Next: Quest 3 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="../assets/shared/quest-navigator.js"></script>
    <!-- Theme Toggle Script (for light/dark mode toggle) -->
    <script src="../assets/theme-toggle.js"></script>
</body>
</html>