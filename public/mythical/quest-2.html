<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mystic LLM Providers - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="../assets/shared/quest-navigator.css">
    <link rel="stylesheet" href="../assets/theme-toggle.css">
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }

        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body class="theme-mythical">

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="https://github.com/Azure-Samples/azure-ai-travel-agents" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="../assets/shared/github-mark.svg" alt="GitHub" width="24" height="24">
                </a>
                <a href="index.html">The Enchanted Kingdom of Multi-Agent Harmony</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Adventure</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <button class="theme-toggle-btn" aria-label="Switch to light mode" type="button">
                    <div class="theme-toggle-slider">
                        <svg class="toggle-icon sun-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="4" fill="currentColor"/>
                            <path d="M12 2v2M12 20v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M2 12h2M20 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                        </svg>
                        <svg class="toggle-icon moon-icon" viewBox="0 0 24 24">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                        </svg>
                    </div>
                </button>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 2: The Enchanted Scrolls of LLM Providers</h1>
<hr>
<p>In the Kingdom of Code, the Mage LlamaIndex.TS entrusted the Mystic Scrolls of LLM Providers to guide agents in channeling their magical abilities. These enchanted scrolls, written in the arcane language of TypeScript, allow the Mage to summon diverse powers from Azure, GitHub, and other realms. But the scrolls‚Äô magic is fragile, relying on precise configurations and the Mage‚Äôs wisdom to select the right provider. Adventurer, delve into the scrolls and unlock the secrets of flexible LLM provider strategies!</p>
<h2>Key Takeaways</h2>
<p>After completing this quest, you will understand:</p>
<ul>
<li>üéØ <strong>Dynamic LLM Configuration</strong>: How the system dynamically selects LLM providers based on environment variables.</li>
<li>üîç <strong>Azure Integration</strong>: How Azure Managed Identity and API Key authentication are implemented for secure LLM access.</li>
<li>‚ö° <strong>Modular Design</strong>: How the provider architecture ensures flexibility and extensibility for adding new LLMs.</li>
<li>üí° <strong>Error Handling</strong>: How the system gracefully handles unknown or unsupported providers.</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/index.ts</code></a></h3>
<p>This file serves as the central orchestration scroll for selecting the appropriate LLM provider. It dynamically determines the provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable and invokes the corresponding configuration function. The modular design ensures that new providers can be added seamlessly without altering the core logic.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function dynamically selects the LLM provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable.</li>
<li><code class="inline-code">LLMProvider</code> type defines valid options, ensuring type safety and clarity.</li>
<li>Error handling ensures graceful failure when an unsupported provider is specified.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">import dotenv from &quot;dotenv&quot;;
dotenv.config();

import { llm as azureOpenAI } from &quot;./azure-openai.js&quot;;
import { llm as foundryLocal } from &quot;./foundry-local.js&quot;;
import { llm as githubModels } from &quot;./github-models.js&quot;;
import { llm as dockerModels } from &quot;./docker-models.js&quot;;
import { llm as ollamaModels } from &quot;./ollama-models.js&quot;;

type LLMProvider =
  | &quot;azure-openai&quot;
  | &quot;github-models&quot;
  | &quot;foundry-local&quot;
  | &quot;docker-models&quot;
  | &quot;ollama-models&quot;;

const provider = (process.env.LLM_PROVIDER || &quot;&quot;) as LLMProvider;

export const llm = async () =&gt; {
  switch (provider) {
    case &quot;azure-openai&quot;:
      return azureOpenAI();
    case &quot;github-models&quot;:
      return githubModels();
    case &quot;docker-models&quot;:
      return dockerModels();
    case &quot;ollama-models&quot;:
      return ollamaModels();
    case &quot;foundry-local&quot;:
      return foundryLocal();
    default:
      throw new Error(
        `Unknown LLM_PROVIDER &quot;${provider}&quot;. Valid options are: azure-openai, github-models, foundry-local, docker-models, ollama-models.`
      );
  }
};
</code></pre>
<ul>
<li>This code dynamically selects the appropriate LLM provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable.</li>
<li>The <code class="inline-code">switch</code> statement ensures each provider is invoked only when explicitly specified, enhancing modularity.</li>
<li>The <code class="inline-code">LLMProvider</code> type guarantees compile-time validation of valid provider options.</li>
<li>Error handling prevents runtime crashes by throwing a descriptive error for unknown providers.</li>
<li>This design simplifies the addition of new providers by isolating their logic in separate modules.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/azure-openai.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/azure-openai.ts</code></a></h3>
<p>This file contains the spell for invoking Azure OpenAI services. It supports both Managed Identity and API Key authentication, ensuring flexibility in various deployment environments. The <code class="inline-code">AZURE_COGNITIVE_SERVICES_SCOPE</code> constant defines the scope for Azure authentication.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function configures Azure OpenAI with either Managed Identity or API Key authentication.</li>
<li><code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code> are used for secure token acquisition.</li>
<li>Environment detection enables local and production-specific configurations.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">import { openai } from &quot;llamaindex&quot;;
import {
  DefaultAzureCredential,
  getBearerTokenProvider,
  ManagedIdentityCredential,
} from &quot;@azure/identity&quot;;

const AZURE_COGNITIVE_SERVICES_SCOPE =
  &quot;https://cognitiveservices.azure.com/.default&quot;;

export const llm = async () =&gt; {
  console.log(&quot;Using Azure OpenAI&quot;);

  const isRunningInLocalDocker = process.env.IS_LOCAL_DOCKER_ENV === &quot;true&quot;;
  
  if (isRunningInLocalDocker) {
    console.log(
      &quot;Running in local Docker environment, Azure Managed Identity is not supported. Authenticating with apiKey.&quot;
    );
    return openai({
      azure: {
        endpoint: process.env.AZURE_OPENAI_ENDPOINT,
        deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
        apiKey: process.env.AZURE_OPENAI_API_KEY,
      },
    });
  }
  
  let credential: any = new DefaultAzureCredential();
  const clientId = process.env.AZURE_CLIENT_ID;
  if (clientId) {
    console.log(&quot;Using Azure Client ID:&quot;, clientId);
    credential = new ManagedIdentityCredential({
      clientId,
    });
  }

  const azureADTokenProvider = getBearerTokenProvider(
    credential,
    AZURE_COGNITIVE_SERVICES_SCOPE
  );

  return openai({
    azure: {
      azureADTokenProvider,
      endpoint: process.env.AZURE_OPENAI_ENDPOINT,
      deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
    },
  });
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function configures Azure OpenAI access with environment-specific authentication mechanisms.</li>
<li>The <code class="inline-code">DefaultAzureCredential</code> class simplifies token acquisition in production environments.</li>
<li>The <code class="inline-code">ManagedIdentityCredential</code> class allows for secure authentication using Azure Managed Identity.</li>
<li>API Key authentication ensures compatibility with local Docker environments, where Managed Identity is unavailable.</li>
<li>The <code class="inline-code">AZURE_COGNITIVE_SERVICES_SCOPE</code> constant defines the required scope for token requests, ensuring proper authorization.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/github-models.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/github-models.ts</code></a></h3>
<p>This file defines the invocation spell for GitHub-hosted models. It relies on API Key authentication and allows flexible model selection via environment variables.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function configures GitHub Models with API Key authentication.</li>
<li>Environment variables enable dynamic configuration of the model endpoint and selection.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">import { openai } from &quot;llamaindex&quot;;

export const llm = async () =&gt; {
  console.log(&quot;Using GitHub Models&quot;);
  return openai({
    baseURL: &quot;https://models.inference.ai.azure.com&quot;,
    apiKey: process.env.GITHUB_TOKEN,
    model: process.env.GITHUB_MODEL,
  });
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function configures GitHub-hosted models using the <code class="inline-code">openai</code> function from LlamaIndex.</li>
<li>The <code class="inline-code">baseURL</code> specifies the endpoint for model inference, ensuring compatibility with GitHub Models.</li>
<li>API Key authentication is implemented through the <code class="inline-code">GITHUB_TOKEN</code> environment variable.</li>
<li>The <code class="inline-code">GITHUB_MODEL</code> environment variable allows dynamic model selection, enhancing flexibility.</li>
<li>This design simplifies integration with GitHub-hosted models while maintaining security through environment-based configuration.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Study how the <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function in each file uses environment variables to enable dynamic configuration.</li>
<li>Explore the use of Azure Managed Identity for secure and scalable authentication in production environments.</li>
<li>Notice how the modular design of LLM providers facilitates the addition of new services without modifying core logic.</li>
</ul>
<h2>Try This</h2>
<p>Challenge yourself to deepen your understanding:</p>
<ol>
<li><p><strong>Add a New Provider</strong>: Implement a new LLM provider that integrates with a hypothetical service called &quot;DragonAI&quot;. Create a new file <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/dragonai.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/dragonai.ts</code></a> and register it in <code class="inline-code">index.ts</code>.</p>
<ul>
<li>Use environment variables to configure the endpoint and API Key for DragonAI.</li>
<li>Test your provider by setting <code class="inline-code">LLM_PROVIDER=dragonai</code> in your <code class="inline-code">.env</code> file.</li>
</ul>
</li>
<li><p><strong>Trace Azure Authentication</strong>: Add <code class="inline-code">console.log</code> statements to trace the token acquisition process in <code class="inline-code">azure-openai.ts</code>. Observe how the <code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code> classes handle authentication.</p>
</li>
<li><p><strong>Enhance Error Messages</strong>: Modify the error handling in <code class="inline-code">index.ts</code> to suggest valid provider options when an unknown provider is specified. This will improve developer experience and reduce debugging time.</p>
</li>
</ol>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries of the enchanted agents and their magical tools.</p>
<p>By the shimmering light of the Celestial Forge, you have unlocked the first arcane milestone of the Mystic LLM Providers quest‚Äîtake heart, brave scholar, for your journey through the realms of knowledge has begun with a triumph worthy of legend! ‚≠ê‚ö°üíé</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-1.html" class="prev-quest-btn">‚Üê Previous: Quest 1</a>
        <a href="quest-3.html" class="next-quest-btn">Next: Quest 3 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="../assets/shared/quest-navigator.js"></script>
    <!-- Theme Toggle Script (for light/dark mode toggle) -->
    <script src="../assets/theme-toggle.js"></script>
</body>
</html>