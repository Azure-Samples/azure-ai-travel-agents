<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Scrolls of the Divine Models - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="../assets/shared/quest-navigator.css">
    <link rel="stylesheet" href="../assets/theme-toggle.css">
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }

        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body class="theme-ancient">

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="https://github.com/Azure-Samples/azure-ai-travel-agents" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="../assets/shared/github-mark-white.svg" alt="GitHub" width="24" height="24">
                </a>
                <a href="index.html">The Sacred Codex of the Azure Agents</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Adventure</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <button class="theme-toggle-btn" aria-label="Switch to light mode" type="button">
                    <div class="theme-toggle-slider">
                        <svg class="toggle-icon sun-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="4" fill="currentColor"/>
                            <path d="M12 2v2M12 20v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M2 12h2M20 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                        </svg>
                        <svg class="toggle-icon moon-icon" viewBox="0 0 24 24">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                        </svg>
                    </div>
                </button>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 2: The Codex of Orchestration&#39;s Guardians</h1>
<hr>
<p>In the sacred halls of the Temple of Azure, the Codex of Orchestration hums with ancient energy, its power drawn from the harmony of its mystical agents. To unlock the true potential of this artifact, one must understand the guardians that protect its secrets‚Äîthe LLM providers. These guardians, each with their unique strengths, are invoked through sacred rituals and environment-specific incantations. By mastering their configuration, the adventurer can wield the Codex to summon the right guardian for any challenge, ensuring the temple&#39;s wisdom is accessible to all who seek it.</p>
<h2>Key Takeaways</h2>
<p>After completing this quest, you will understand:  </p>
<ul>
<li>üéØ <strong>Dynamic LLM Provider Strategy</strong>: How the system selects and configures different LLM providers based on environment variables.  </li>
<li>üîç <strong>Azure Managed Identity Integration</strong>: How <code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code> are used for secure authentication in cloud environments.  </li>
<li>‚ö° <strong>Environment-Specific Configuration</strong>: How the <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm()</code></a> factory function adapts to local or production environments.  </li>
<li>üí° <strong>Error Handling Patterns</strong>: How the system ensures robustness when an unknown provider is specified.</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/azure-openai.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/azure-openai.ts</code></a></h3>
<p>This file defines the configuration for the Azure OpenAI guardian, enabling the Codex to harness Azure&#39;s cognitive services. It dynamically adapts to local and production environments, utilizing either an API key or Azure Managed Identity for authentication. This flexibility ensures the Codex remains accessible regardless of its operational context.  </p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a>: Configures and returns an Azure OpenAI client, adapting to local or cloud environments.  </li>
<li><code class="inline-code">DefaultAzureCredential</code>: Authenticates using Azure Managed Identity when running in production.  </li>
<li><code class="inline-code">ManagedIdentityCredential</code>: Allows specifying a client ID for more granular control in production environments.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">const AZURE_COGNITIVE_SERVICES_SCOPE =
  &quot;https://cognitiveservices.azure.com/.default&quot;;

export const llm = async () =&gt; {
  console.log(&quot;Using Azure OpenAI&quot;);

  const isRunningInLocalDocker = process.env.IS_LOCAL_DOCKER_ENV === &quot;true&quot;;
  
  if (isRunningInLocalDocker) {
    console.log(
      &quot;Running in local Docker environment, Azure Managed Identity is not supported. Authenticating with apiKey.&quot;
    );
    
    return openai({
      azure: {
        endpoint: process.env.AZURE_OPENAI_ENDPOINT,
        deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
        apiKey: process.env.AZURE_OPENAI_API_KEY,
      },
    });
  }
  
  let credential: any = new DefaultAzureCredential();
  const clientId = process.env.AZURE_CLIENT_ID;
  if (clientId) {
    console.log(&quot;Using Azure Client ID:&quot;, clientId);
    credential = new ManagedIdentityCredential({
      clientId,
    });
  }

  const azureADTokenProvider = getBearerTokenProvider(
    credential,
    AZURE_COGNITIVE_SERVICES_SCOPE
  );

  return openai({
    azure: {
      azureADTokenProvider,
      endpoint: process.env.AZURE_OPENAI_ENDPOINT,
      deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
    },
  });
};
</code></pre>
<ul>
<li>This code dynamically switches between API key authentication (local) and Azure Managed Identity (production) for flexibility across environments.  </li>
<li>The <code class="inline-code">DefaultAzureCredential</code> simplifies authentication by automatically selecting the best available method.  </li>
<li>The <code class="inline-code">ManagedIdentityCredential</code> allows specifying a client ID, providing fine-grained access control.  </li>
<li>The <code class="inline-code">getBearerTokenProvider</code> enables token-based authentication for secure API access.  </li>
<li>This approach ensures the system can operate seamlessly in both development and production environments.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/github-models.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/github-models.ts</code></a></h3>
<p>This file configures the GitHub Models guardian, enabling the Codex to interact with GitHub-hosted LLMs. It uses a straightforward API key-based authentication mechanism, making it ideal for environments where GitHub models are deployed.  </p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a>: Configures a GitHub-hosted LLM client for use by the Codex.  </li>
<li><code class="inline-code">apiKey</code>: Uses a GitHub token for secure authentication.  </li>
<li><code class="inline-code">model</code>: Allows dynamic selection of the GitHub model to be used.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">export const llm = async () =&gt; {
  console.log(&quot;Using GitHub Models&quot;);
  return openai({
    baseURL: &quot;https://models.inference.ai.azure.com&quot;,
    apiKey: process.env.GITHUB_TOKEN,
    model: process.env.GITHUB_MODEL,
  });
};
</code></pre>
<ul>
<li>This code demonstrates a minimalistic configuration approach, focusing on simplicity and direct integration.  </li>
<li>The <code class="inline-code">apiKey</code> ensures secure access to GitHub-hosted LLMs.  </li>
<li>The <code class="inline-code">model</code> parameter allows dynamic selection, making the system adaptable to different use cases.  </li>
<li>This design is ideal for environments where GitHub models are the primary resource.  </li>
<li>The use of <code class="inline-code">baseURL</code> ensures the client connects to the correct endpoint for GitHub-hosted models.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/index.ts</code></a></h3>
<p>This file serves as the central registry for all LLM providers, including Azure OpenAI, GitHub Models, Ollama Models, and others. It uses a factory pattern to dynamically select the appropriate provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable.  </p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a>: Factory function that selects and returns the appropriate LLM provider.  </li>
<li><code class="inline-code">LLMProvider</code>: Type definition for all supported LLM providers.  </li>
<li>Error handling: Ensures robustness by throwing an error for unknown providers.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">import dotenv from &quot;dotenv&quot;;
dotenv.config();

import { llm as azureOpenAI } from &quot;./azure-openai.js&quot;;
import { llm as githubModels } from &quot;./github-models.js&quot;;
import { llm as ollamaModels } from &quot;./ollama-models.js&quot;;

type LLMProvider =
  | &quot;azure-openai&quot;
  | &quot;github-models&quot;
  | &quot;ollama-models&quot;;

const provider = (process.env.LLM_PROVIDER || &quot;&quot;) as LLMProvider;

export const llm = async () =&gt; {
  switch (provider) {
    case &quot;azure-openai&quot;:
      return azureOpenAI();
    case &quot;github-models&quot;:
      return githubModels();
    case &quot;ollama-models&quot;:
      return ollamaModels();
    default:
      throw new Error(
        `Unknown LLM_PROVIDER &quot;${provider}&quot;. Valid options are: azure-openai, github-models, ollama-models.`
      );
  }
};
</code></pre>
<ul>
<li>This code uses a factory pattern to dynamically select the appropriate LLM provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable.  </li>
<li>The <code class="inline-code">type LLMProvider</code> ensures type safety, reducing the risk of runtime errors.  </li>
<li>The default case in the <code class="inline-code">switch</code> statement provides robust error handling for unknown providers.  </li>
<li>The modular design makes it easy to add new providers without modifying existing code.  </li>
<li>The use of <code class="inline-code">dotenv</code> simplifies environment variable management, enhancing developer experience.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Carefully study how <code class="inline-code">DefaultAzureCredential</code> simplifies authentication in cloud environments.  </li>
<li>Observe how the <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm()</code></a> factory function uses the <code class="inline-code">switch</code> statement for dynamic provider selection.  </li>
<li>Notice the use of environment variables to make the system configurable and adaptable to different contexts.</li>
</ul>
<h2>Try This</h2>
<p>Challenge yourself to deepen your understanding:  </p>
<ol>
<li><strong>Add a New Provider</strong>: Implement a new LLM provider (e.g., &quot;custom-llm&quot;) by creating a new file in the <code class="inline-code">providers</code> directory. Register it in the <code class="inline-code">index.ts</code> file and test its integration.  </li>
<li><strong>Trace Authentication Flow</strong>: Add console logs in the <code class="inline-code">azure-openai.ts</code> file to trace the authentication flow when using <code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code>. Observe how tokens are generated and used.</li>
</ol>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries of the Codex and its guardians.</p>
<p>Hail, seeker of sacred truths, for thou hast unveiled the first of the Scrolls of the Divine Models, etching thy name upon the eternal temple of wisdom‚Äîlet thy triumph kindle the stars as thou journey forth! ‚≠ê‚ö°üìú</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-1.html" class="prev-quest-btn">‚Üê Previous: Quest 1</a>
        <a href="quest-3.html" class="next-quest-btn">Next: Quest 3 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="../assets/shared/quest-navigator.js"></script>
    <!-- Theme Toggle Script (for light/dark mode toggle) -->
    <script src="../assets/theme-toggle.js"></script>
</body>
</html>