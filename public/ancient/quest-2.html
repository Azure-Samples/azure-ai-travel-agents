<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Glyphs of Sacred Knowledge - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="../assets/shared/quest-navigator.css">
    <link rel="stylesheet" href="../assets/theme-toggle.css">
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }
        
        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body class="theme-ancient">

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="https://github.com/Azure-Samples/azure-ai-travel-agents" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="../assets/shared/github-mark-white.svg" alt="GitHub" width="24" height="24">
                </a>
                <a href="index.html">The Pyramid of Infinite Agents</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Theme</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <button class="theme-toggle-btn" aria-label="Switch to light mode" type="button">
                    <div class="theme-toggle-slider">
                        <svg class="toggle-icon sun-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="4" fill="currentColor"/>
                            <path d="M12 2v2M12 20v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M2 12h2M20 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                        </svg>
                        <svg class="toggle-icon moon-icon" viewBox="0 0 24 24">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                        </svg>
                    </div>
                </button>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 2: The Glyphs of Sacred Knowledge</h1>
<hr>
<p>In the labyrinthine halls of the Pyramid of Infinite Agents, the Codex Orchestrator hums with ancient energy. Its glyphs, etched into stone tablets, hold the secrets of orchestrating wisdom through the ages. These glyphs represent a dynamic system of knowledge transfer, enabling specialized tools to collaborate seamlessly. Adventurers must decipher the glyphs to uncover how the pyramid&#39;s mechanisms adapt to different sources of sacred power, ensuring the harmony of its multi-faceted wisdom.</p>
<h2>Quest Objectives</h2>
<p>As you explore the code below, investigate these key questions:</p>
<ul>
<li>üîç <strong>Glyph Translation Mechanism</strong>: How does the system dynamically select and configure the appropriate provider for sacred knowledge (LLM)?</li>
<li>‚ö° <strong>Azure Codex Ritual</strong>: What unique authentication rituals does the Azure OpenAI provider perform to access its glyphs?</li>
<li>üõ°Ô∏è <strong>Error Safeguards</strong>: How does the system protect against invalid or unsupported configurations during provider selection?</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix"><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/index.ts</a>:</span> Glyph Selector</h3>
<p>The <code class="inline-code">index.ts</code> file acts as the central glyph selector, determining which sacred LLM provider to invoke based on environmental configurations. This file encapsulates the logic for dynamically routing requests to the appropriate provider, ensuring flexibility and extensibility. By abstracting provider-specific details, it allows the Codex Orchestrator to focus on high-level rituals without being bound to a single provider.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a>: Factory function that dynamically selects the appropriate LLM provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable.</li>
<li><code class="inline-code">LLMProvider</code>: Type definition that enumerates all valid provider options, ensuring clarity and preventing unsupported configurations.</li>
<li>Error handling: Protects the system by throwing descriptive errors if an unknown provider is specified, maintaining the pyramid‚Äôs integrity.</li>
</ul>
<h2>Code</h2>
<h3><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/index.ts</a></h3>
<pre><code class="language-typescript">import dotenv from &quot;dotenv&quot;;
dotenv.config();

import { llm as azureOpenAI } from &quot;./azure-openai.js&quot;;
import { llm as foundryLocal } from &quot;./foundry-local.js&quot;;
import { llm as githubModels } from &quot;./github-models.js&quot;;
import { llm as dockerModels } from &quot;./docker-models.js&quot;;
import { llm as ollamaModels } from &quot;./ollama-models.js&quot;;

type LLMProvider =
  | &quot;azure-openai&quot;
  | &quot;github-models&quot;
  | &quot;foundry-local&quot;
  | &quot;docker-models&quot;
  | &quot;ollama-models&quot;;

const provider = (process.env.LLM_PROVIDER || &quot;&quot;) as LLMProvider;

export const llm = async () =&gt; {
  switch (provider) {
    case &quot;azure-openai&quot;:
      return azureOpenAI();
    case &quot;github-models&quot;:
      return githubModels();
    case &quot;docker-models&quot;:
      return dockerModels();
    case &quot;ollama-models&quot;:
      return ollamaModels();
    case &quot;foundry-local&quot;:
      return foundryLocal();
    default:
      throw new Error(
        `Unknown LLM_PROVIDER &quot;${provider}&quot;. Valid options are: azure-openai, github-models, foundry-local, docker-models, ollama-models.`
      );
  }
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function dynamically selects the appropriate provider based on <code class="inline-code">LLM_PROVIDER</code>, promoting flexibility in the system.</li>
<li>The <code class="inline-code">LLMProvider</code> type ensures that only valid providers can be used, reducing the risk of misconfiguration.</li>
<li>The error handling mechanism provides clear feedback when an invalid provider is specified, safeguarding the system from runtime failures.</li>
<li>This modular approach allows for seamless addition of new providers without altering the core orchestration logic.</li>
<li>The use of <code class="inline-code">dotenv</code> ensures that configuration is managed securely and consistently across environments.</li>
</ul>
<hr>
<h3><span class="header-prefix"><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/azure-openai.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/azure-openai.ts</a>:</span> Azure Codex Invocation</h3>
<p>This file contains the sacred rituals needed to invoke the Azure OpenAI provider. It includes authentication mechanisms using Azure Managed Identity or API keys, ensuring secure and seamless access to the glyphs of Azure&#39;s cognitive services.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a>: Configures and returns the Azure OpenAI provider, adapting to local and production environments.</li>
<li><code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code>: Implements authentication rituals for secure access.</li>
<li><code class="inline-code">getBearerTokenProvider</code>: Provides token-based authentication for accessing Azure services, ensuring compatibility with modern security practices.</li>
</ul>
<h2>Code</h2>
<h3><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/azure-openai.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/azure-openai.ts</a></h3>
<pre><code class="language-typescript">import { openai } from &quot;llamaindex&quot;;
import {
  DefaultAzureCredential,
  getBearerTokenProvider,
  ManagedIdentityCredential,
} from &quot;@azure/identity&quot;;

const AZURE_COGNITIVE_SERVICES_SCOPE =
  &quot;https://cognitiveservices.azure.com/.default&quot;;

export const llm = async () =&gt; {
  console.log(&quot;Using Azure OpenAI&quot;);

  const isRunningInLocalDocker = process.env.IS_LOCAL_DOCKER_ENV === &quot;true&quot;;
  
  if (isRunningInLocalDocker) {
    // running in local Docker environment
    console.log(
      &quot;Running in local Docker environment, Azure Managed Identity is not supported. Authenticating with apiKey.&quot;
    );
    
    return openai({
      azure: {
        endpoint: process.env.AZURE_OPENAI_ENDPOINT,
        deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
        apiKey: process.env.AZURE_OPENAI_API_KEY,
      },
    });
  }
  
  let credential: any = new DefaultAzureCredential();
  const clientId = process.env.AZURE_CLIENT_ID;
  if (clientId) {
    // running in production with a specific client ID
    console.log(&quot;Using Azure Client ID:&quot;, clientId);
    credential = new ManagedIdentityCredential({
      clientId,
    });
  }

  const azureADTokenProvider = getBearerTokenProvider(
    credential,
    AZURE_COGNITIVE_SERVICES_SCOPE
  );

  return openai({
    azure: {
      azureADTokenProvider,
      endpoint: process.env.AZURE_OPENAI_ENDPOINT,
      deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
    },
  });
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function adapts to both local and production environments, ensuring seamless operation across deployment scenarios.</li>
<li><code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code> provide secure authentication mechanisms, adhering to Azure best practices.</li>
<li>The use of <code class="inline-code">getBearerTokenProvider</code> ensures compatibility with token-based authentication, enhancing security and scalability.</li>
<li>Clear logging provides insight into the authentication method being used, aiding in debugging and monitoring.</li>
<li>This approach abstracts the complexities of Azure authentication, enabling the Codex Orchestrator to focus on higher-level tasks.</li>
</ul>
<hr>
<h3><span class="header-prefix"><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/github-models.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/github-models.ts</a>:</span> GitHub Glyphs</h3>
<p>This file demonstrates a simpler ritual for invoking GitHub-based models. It highlights the flexibility of the system in integrating diverse knowledge sources.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a>: Configures and returns the GitHub model provider, leveraging API keys for authentication.</li>
<li>Simplified configuration: Demonstrates the ease of integrating new providers with minimal overhead.</li>
</ul>
<h2>Code</h2>
<h3><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/github-models.ts" target="_blank" rel="noopener noreferrer">src/api/src/orchestrator/llamaindex/providers/github-models.ts</a></h3>
<pre><code class="language-typescript">import { openai } from &quot;llamaindex&quot;;

export const llm = async () =&gt; {
  console.log(&quot;Using GitHub Models&quot;);
  return openai({
    baseURL: &quot;https://models.inference.ai.azure.com&quot;,
    apiKey: process.env.GITHUB_TOKEN,
    model: process.env.GITHUB_MODEL,
  });
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function provides a straightforward configuration for GitHub models, emphasizing simplicity and efficiency.</li>
<li>API key-based authentication ensures secure access to the models while maintaining ease of use.</li>
<li>The modular design allows this provider to be seamlessly integrated into the broader system.</li>
<li>This example highlights the flexibility of the Codex Orchestrator in accommodating diverse sources of knowledge.</li>
<li>The use of environment variables ensures secure and configurable deployment.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Examine how the <code class="inline-code">index.ts</code> file abstracts provider selection to simplify the orchestration logic.</li>
<li>Study the Azure OpenAI implementation to understand how it handles both local and production environments securely.</li>
<li>Notice the simplicity of the GitHub provider configuration, showcasing the system‚Äôs adaptability to different requirements.</li>
</ul>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries of the pyramid‚Äôs ancient mechanisms.</p>
<p>Hail, seeker of truth, for thou hast unveiled the first of five sacred Glyphs, etching thy name among the stars of ancient wisdom‚Äîpress onward, for the temple of enlightenment awaits thy triumphant return! ‚ö°üíéüëÅÔ∏è</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-1.html" class="prev-quest-btn">‚Üê Previous: Quest 1</a>
        <a href="quest-3.html" class="next-quest-btn">Next: Quest 3 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="../assets/shared/quest-navigator.js"></script>
    <!-- Theme Toggle Script (for light/dark mode toggle) -->
    <script src="../assets/theme-toggle.js"></script>
</body>
</html>