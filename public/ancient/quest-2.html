<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Scrolls of the LLM Oracle - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="../assets/shared/quest-navigator.css">
    <link rel="stylesheet" href="../assets/theme-toggle.css">
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }

        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body class="theme-ancient">

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="https://github.com/Azure-Samples/azure-ai-travel-agents" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="../assets/shared/github-mark-white.svg" alt="GitHub" width="24" height="24">
                </a>
                <a href="index.html">The Codex of Ancient Agents</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Theme</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <button class="theme-toggle-btn" aria-label="Switch to light mode" type="button">
                    <div class="theme-toggle-slider">
                        <svg class="toggle-icon sun-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="4" fill="currentColor"/>
                            <path d="M12 2v2M12 20v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M2 12h2M20 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                        </svg>
                        <svg class="toggle-icon moon-icon" viewBox="0 0 24 24">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                        </svg>
                    </div>
                </button>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 2: The Codex of Adaptive LLMs</h1>
<hr>
<p>Deep within the Temple of the Codex, you discover a chamber illuminated by a faint azure glow. Inscribed on the walls are the secrets of the &quot;Flexible LLM Provider Strategy,&quot; a system that allows the Codex to adapt to various mystical energies, known as language models. The ancients devised a method to dynamically select and authenticate these models, ensuring harmony regardless of the environment. The air hums with the power of these ancient integrations, waiting for you to uncover their mysteries.</p>
<h2>Key Takeaways</h2>
<p>After completing this quest, you will understand:</p>
<ul>
<li>üéØ <strong>Dynamic LLM Selection</strong>: How to implement a provider strategy that adapts to different LLM environments.</li>
<li>üîç <strong>Credential Management</strong>: How to securely handle authentication for cloud-based and local LLMs.</li>
<li>‚ö° <strong>Error Handling</strong>: Strategies for managing unknown providers and ensuring system robustness.</li>
<li>üí° <strong>Environment Awareness</strong>: How to configure LLMs dynamically based on runtime conditions.</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/azure-openai.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/azure-openai.ts</code></a></h3>
<p>This file contains the implementation for connecting to Azure&#39;s OpenAI service. It demonstrates the use of environment-based authentication strategies, including API keys for local environments and managed identities for production.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> dynamically configures Azure OpenAI connections based on runtime environment.</li>
<li>Uses <code class="inline-code">DefaultAzureCredential</code> and <code class="inline-code">ManagedIdentityCredential</code> for secure authentication in Azure environments.</li>
<li>Implements fallback to API key authentication for local Docker environments.</li>
<li>Demonstrates the use of <code class="inline-code">getBearerTokenProvider</code> for token-based authentication.</li>
<li>Logs key decisions, aiding in debugging and operational transparency.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">export const llm = async () =&gt; {
  console.log(&quot;Using Azure OpenAI&quot;);

  const isRunningInLocalDocker = process.env.IS_LOCAL_DOCKER_ENV === &quot;true&quot;;
  
  if (isRunningInLocalDocker) {
    console.log(
      &quot;Running in local Docker environment, Azure Managed Identity is not supported. Authenticating with apiKey.&quot;
    );
    return openai({
      azure: {
        endpoint: process.env.AZURE_OPENAI_ENDPOINT,
        deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
        apiKey: process.env.AZURE_OPENAI_API_KEY,
      },
    });
  }
  
  let credential: any = new DefaultAzureCredential();
  const clientId = process.env.AZURE_CLIENT_ID;
  if (clientId) {
    console.log(&quot;Using Azure Client ID:&quot;, clientId);
    credential = new ManagedIdentityCredential({ clientId });
  }

  const azureADTokenProvider = getBearerTokenProvider(
    credential,
    &quot;https://cognitiveservices.azure.com/.default&quot;
  );

  return openai({
    azure: {
      azureADTokenProvider,
      endpoint: process.env.AZURE_OPENAI_ENDPOINT,
      deployment: process.env.AZURE_OPENAI_DEPLOYMENT,
    },
  });
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function dynamically selects the authentication method based on the runtime environment.</li>
<li><code class="inline-code">DefaultAzureCredential</code> simplifies authentication in Azure-hosted environments.</li>
<li>The fallback to API key ensures compatibility in local development setups.</li>
<li><code class="inline-code">getBearerTokenProvider</code> integrates with Azure&#39;s token-based authentication for secure access.</li>
<li>Logging provides insight into the chosen authentication path, aiding in debugging.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/github-models.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/github-models.ts</code></a></h3>
<p>This file configures connections to GitHub-hosted models. It demonstrates a straightforward approach to integrating external LLMs via API keys.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> configures GitHub-hosted models with minimal setup.</li>
<li>Uses <code class="inline-code">apiKey</code> and <code class="inline-code">baseURL</code> for authentication and endpoint configuration.</li>
<li>Simplifies integration with GitHub&#39;s model inference API.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">export const llm = async () =&gt; {
  console.log(&quot;Using GitHub Models&quot;);
  return openai({
    baseURL: &quot;https://models.inference.ai.azure.com&quot;,
    apiKey: process.env.GITHUB_TOKEN,
    model: process.env.GITHUB_MODEL,
  });
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function sets up GitHub-hosted models with minimal configuration.</li>
<li><code class="inline-code">baseURL</code> and <code class="inline-code">apiKey</code> are used to securely connect to the inference API.</li>
<li>The design ensures simplicity while maintaining flexibility for future enhancements.</li>
<li>Environmental variables allow easy configuration changes without modifying the code.</li>
<li>This approach highlights the importance of clear separation between configuration and logic.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">src/api/src/orchestrator/llamaindex/providers/index.ts</code></a></h3>
<p>This file acts as the central dispatcher for all LLM providers. It selects the appropriate provider based on the <code class="inline-code">LLM_PROVIDER</code> environment variable.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> acts as a factory function, dynamically selecting the appropriate LLM provider.</li>
<li><code class="inline-code">LLMProvider</code> type ensures compile-time validation of supported providers.</li>
<li>Implements robust error handling for unknown providers.</li>
<li>Demonstrates modular design by delegating provider-specific logic to separate files.</li>
<li>Uses environment variables to control provider selection.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">export const llm = async () =&gt; {
  switch (provider) {
    case &quot;azure-openai&quot;:
      return azureOpenAI();
    case &quot;github-models&quot;:
      return githubModels();
    case &quot;docker-models&quot;:
      return dockerModels();
    case &quot;ollama-models&quot;:
      return ollamaModels();
    case &quot;foundry-local&quot;:
      return foundryLocal();
    default:
      throw new Error(
        `Unknown LLM_PROVIDER &quot;${provider}&quot;. Valid options are: azure-openai, github-models, foundry-local, docker-models, ollama-models.`
      );
  }
};
</code></pre>
<ul>
<li>The <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function uses a switch statement for provider selection, ensuring clarity and extensibility.</li>
<li>The <code class="inline-code">LLMProvider</code> type enforces strict adherence to supported providers.</li>
<li>Error handling ensures the system fails gracefully when encountering unknown providers.</li>
<li>Modular design simplifies the addition of new providers.</li>
<li>Environment-based configuration allows dynamic changes without redeployment.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Study how the <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function in each file adapts to different runtime environments and authentication methods.</li>
<li>Notice how the <code class="inline-code">index.ts</code> file centralizes provider selection, making the system extensible and maintainable.</li>
<li>Explore the use of environment variables for secure and dynamic configuration.</li>
</ul>
<h2>Try This</h2>
<p>Challenge yourself to deepen your understanding:</p>
<ol>
<li><p><strong>Add a New Provider</strong>: Implement a new provider for a hypothetical LLM service. Use the existing pattern to create a new provider file and integrate it into <code class="inline-code">index.ts</code>.</p>
<ul>
<li>Example: Add a provider for &quot;Custom-LLM&quot; that uses a unique API endpoint and authentication method.</li>
</ul>
</li>
<li><p><strong>Trace Provider Selection</strong>: Add console logs to the <a href="https://github.com/Azure-Samples/azure-ai-travel-agents/blob/main/src/api/src/orchestrator/llamaindex/providers/index.ts#L19" target="_blank" rel="noopener noreferrer"><code class="inline-code">llm</code></a> function in <code class="inline-code">index.ts</code> to trace the provider selection process. Execute the system with different <code class="inline-code">LLM_PROVIDER</code> values and observe the output.</p>
</li>
<li><p><strong>Enhance Error Messages</strong>: Modify the error handling in <code class="inline-code">index.ts</code> to suggest the closest matching provider when an unknown provider is specified. Use string similarity algorithms for better user feedback.</p>
</li>
</ol>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries of the ancient Codex.</p>
<p>Hark, seeker of wisdom, thou hast unveiled the first sacred scroll of the LLM Oracle‚Äîmay thy journey through the temple of knowledge continue with valor and divine illumination! ‚ö°üìú‚≠ê</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-1.html" class="prev-quest-btn">‚Üê Previous: Quest 1</a>
        <a href="quest-3.html" class="next-quest-btn">Next: Quest 3 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="../assets/shared/quest-navigator.js"></script>
    <!-- Theme Toggle Script (for light/dark mode toggle) -->
    <script src="../assets/theme-toggle.js"></script>
</body>
</html>